[
  {
    "custom_node": "ComfyUI_IPAdapter_plus",
    "reference": "https://github.com/cubiq/ComfyUI_IPAdapter_plus",
    "models": {
      "files": [
        {
          "name": "CLIP-ViT-H-14-laion2B-s32B-b79K",
          "type": "IP-Adapter",
          "base": "SD1.5",
          "save_path": "clip_vision",
          "description": "image encoder for SD1.5",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/model.safetensors"
        },
        {
          "name": "CLIP-ViT-bigG-14-laion2B-39B-b160k",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "clip_vision",
          "description": "image encoder for SDXL",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "CLIP-ViT-bigG-14-laion2B-39B-b160k.safetensors",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/image_encoder/model.safetensors"
        },
        {
          "name": "clip-vit-large-patch14-336",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "clip_vision",
          "description": "image encoder for kolors",
          "reference": "https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus",
          "filename": "clip-vit-large-patch14-336.bin",
          "url": "https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus/resolve/main/image_encoder/pytorch_model.bin"
        },
        {
          "name": "ip-adapter_sd15",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "ipadapter",
          "description": "Basic model, average strength",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "ip-adapter_sd15.safetensors",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15.safetensors"
        },
        {
          "name": "ip-adapter_sd15_light_v11",
          "type": "IP-Adapter",
          "base": "SD1.5",
          "save_path": "ipadapter",
          "description": "Light impact model",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "ip-adapter_sd15_light_v11.bin",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15_light_v11.bin"
        },
        {
          "name": "ip-adapter-plus_sd15",
          "type": "IP-Adapter",
          "base": "SD1.5",
          "save_path": "ipadapter",
          "description": "Plus model, very strong",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "ip-adapter-plus_sd15.safetensors",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-plus_sd15.safetensors"
        },
        {
          "name": "ip-adapter-plus-face_sd15",
          "type": "IP-Adapter",
          "base": "SD1.5",
          "save_path": "ipadapter",
          "description": "Face model, portraits",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "ip-adapter-plus-face_sd15.safetensors",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-plus-face_sd15.safetensors"
        },
        {
          "name": "ip-adapter-full-face_sd15",
          "type": "IP-Adapter",
          "base": "SD1.5",
          "save_path": "ipadapter",
          "description": "Stronger face model, not necessarily better",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "ip-adapter-full-face_sd15.safetensors",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-full-face_sd15.safetensors"
        },
        {
          "name": "ip-adapter_sd15_vit-G",
          "type": "IP-Adapter",
          "base": "SD1.5",
          "save_path": "ipadapter",
          "description": "Base model, requires bigG clip vision encoder",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "ip-adapter_sd15_vit-G.safetensors",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15_vit-G.safetensors"
        },
        {
          "name": "ip-adapter_sdxl_vit-h",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "ipadapter",
          "description": "SDXL model",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "ip-adapter_sdxl_vit-h.safetensors",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl_vit-h.safetensors"
        },
        {
          "name": "ip-adapter-plus_sdxl_vit-h",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "ipadapter",
          "description": "SDXL plus model",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "ip-adapter-plus_sdxl_vit-h.safetensors",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter-plus_sdxl_vit-h.safetensors"
        },
        {
          "name": "ip-adapter-plus-face_sdxl_vit-h",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "ipadapter",
          "description": "SDXL face model",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "ip-adapter-plus-face_sdxl_vit-h.safetensors",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter-plus-face_sdxl_vit-h.safetensors"
        },
        {
          "name": "ip-adapter_sdxl",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "ipadapter",
          "description": "vit-G SDXL model, requires bigG clip vision encoder",
          "reference": "https://huggingface.co/h94/IP-Adapter",
          "filename": "ip-adapter_sdxl.safetensors",
          "url": "https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl.safetensors"
        },
        {
          "name": "ip-adapter-faceid_sd15.bin",
          "type": "IP-Adapter",
          "base": "SD1.5",
          "save_path": "ipadapter",
          "description": "IP-Adapter-FaceID Model (SD1.5)",
          "reference": "https://huggingface.co/h94/IP-Adapter-FaceID",
          "filename": "ip-adapter-faceid_sd15.bin",
          "url": "https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sd15.bin"
        },
        {
          "name": "ip-adapter-faceid-plusv2_sd15",
          "type": "IP-Adapter",
          "base": "SD1.5",
          "save_path": "ipadapter",
          "description": "FaceID plus v2",
          "reference": "https://huggingface.co/h94/IP-Adapter-FaceID",
          "filename": "ip-adapter-faceid-plusv2_sd15.bin",
          "url": "https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plusv2_sd15.bin"
        },
        {
          "name": "ip-adapter-faceid-portrait-v11_sd15",
          "type": "IP-Adapter",
          "base": "SD1.5",
          "save_path": "ipadapter",
          "description": "text prompt style transfer for portraits",
          "reference": "https://huggingface.co/h94/IP-Adapter-FaceID",
          "filename": "ip-adapter-faceid-portrait-v11_sd15.bin",
          "url": "https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-portrait-v11_sd15.bin"
        },
        {
          "name": "ip-adapter-faceid_sdxl",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "ipadapter",
          "description": "SDXL base FaceID",
          "reference": "https://huggingface.co/h94/IP-Adapter-FaceID",
          "filename": "ip-adapter-faceid_sdxl.bin",
          "url": "https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid_sdxl.bin"
        },
        {
          "name": "ip-adapter-faceid-plusv2_sdxl",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "ipadapter",
          "description": "SDXL plus v2",
          "reference": "https://huggingface.co/h94/IP-Adapter-FaceID",
          "filename": "ip-adapter-faceid-plusv2_sdxl.bin",
          "url": "https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-plusv2_sdxl.bin"
        },
        {
          "name": "ip-adapter-faceid-portrait_sdxl",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "ipadapter",
          "description": "SDXL text prompt style transfer",
          "reference": "https://huggingface.co/h94/IP-Adapter-FaceID",
          "filename": "ip-adapter-faceid-portrait_sdxl.bin",
          "url": "https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-portrait_sdxl.bin"
        },
        {
          "name": "ip-adapter-faceid-portrait_sdxl_unnorm",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "ipadapter",
          "description": "SDXL text prompt style transfer",
          "reference": "https://huggingface.co/h94/IP-Adapter-FaceID",
          "filename": "ip-adapter-faceid-portrait_sdxl_unnorm.bin",
          "url": "https://huggingface.co/h94/IP-Adapter-FaceID/resolve/main/ip-adapter-faceid-portrait_sdxl_unnorm.bin"
        },
        {
          "name": "Kolors-IP-Adapter-Plus",
          "type": "IP-Adapter",
          "base": "SDXL",
          "save_path": "ipadapter",
          "description": "IPAdapter Plus for Kolors model",
          "reference": "https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus",
          "filename": "Kolors-IP-Adapter-Plus.bin",
          "url": "https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus/resolve/main/ip_adapter_plus_general.bin"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI_InstantID",
    "reference": "https://github.com/cubiq/ComfyUI_InstantID",
    "models": {
      "files": [
        {
          "name": "instantid/ip-adapter.bin",
          "type": "instantid",
          "base": "",
          "save_path": "instantid",
          "description": "InstantID: Zero-shot Identity-Preserving Generation in Seconds",
          "reference": "https://huggingface.co/InstantX/InstantID",
          "filename": "ip-adapter.bin",
          "url": "https://huggingface.co/InstantX/InstantID/resolve/main/ip-adapter.bin"
        },
        {
          "name": "instantid/diffusion_pytorch_model.safetensors",
          "type": "controlnet",
          "base": "",
          "save_path": "controlnet/instantid",
          "description": "controlnet for instantid",
          "reference": "https://huggingface.co/InstantX/InstantID",
          "filename": "diffusion_pytorch_model.safetensors",
          "url": "https://huggingface.co/InstantX/InstantID/resolve/main/ControlNetModel/diffusion_pytorch_model.safetensors"
        },
        {
          "name": "antelopev2",
          "type": "insightface",
          "base": "",
          "save_path": "insightface/models/antelopev2",
          "description": "InsightFace model",
          "reference": "https://huggingface.co/MonsterMMORPG",
          "filename": "antelopev2.zip",
          "url": "https://huggingface.co/MonsterMMORPG/tools/resolve/main/antelopev2.zip"
        }
      ]
    }
  },
  {
    "custom_node": "PuLID_ComfyUI",
    "reference": "https://github.com/cubiq/PuLID_ComfyUI",
    "models": {
      "files": [
        {
          "name": "pulid/ip-adapter_pulid_sdxl_fp16",
          "type": "pulid",
          "base": "SDXL",
          "save_path": "pulid",
          "description": "PuLID pre-trained model, Chenlei Hu for converting them into IPAdapter format",
          "reference": "https://huggingface.co/huchenlei/ipadapter_pulid",
          "filename": "ip-adapter_pulid_sdxl_fp16.safetensors",
          "url": "https://huggingface.co/huchenlei/ipadapter_pulid/resolve/main/ip-adapter_pulid_sdxl_fp16.safetensors"
        },
        {
          "name": "antelopev2",
          "type": "insightface",
          "base": "",
          "save_path": "insightface/models/antelopev2",
          "description": "InsightFace model",
          "reference": "https://huggingface.co/MonsterMMORPG",
          "filename": "antelopev2.zip",
          "url": "https://huggingface.co/MonsterMMORPG/tools/resolve/main/antelopev2.zip"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-IC-Light",
    "reference": "https://github.com/kijai/ComfyUI-IC-Light",
    "models": {
      "files": [
        {
          "name": "IC-Light/fc",
          "type": "IC-Light",
          "base": "SD1.5",
          "save_path": "unet/IC-Light",
          "description": "The default relighting model, conditioned on text and foreground",
          "reference": "https://huggingface.co/lllyasviel/ic-light",
          "filename": "iclight_sd15_fc.safetensors",
          "url": "https://huggingface.co/lllyasviel/ic-light/resolve/main/iclight_sd15_fc.safetensors"
        },
        {
          "name": "IC-Light/fbc",
          "type": "IC-Light",
          "base": "SD1.5",
          "save_path": "unet/IC-Light",
          "description": "Relighting model conditioned with text, foreground, and background",
          "reference": "https://huggingface.co/lllyasviel/ic-light",
          "filename": "iclight_sd15_fbc.safetensors",
          "url": "https://huggingface.co/lllyasviel/ic-light/resolve/main/iclight_sd15_fbc.safetensors"
        },
        {
          "name": "IC-Light/fcon",
          "type": "IC-Light",
          "base": "SD1.5",
          "save_path": "unet/IC-Light",
          "description": "Same as iclight_sd15_fc.safetensors, but trained with offset noise",
          "reference": "https://huggingface.co/lllyasviel/ic-light",
          "filename": "iclight_sd15_fcon.safetensors",
          "url": "https://huggingface.co/lllyasviel/ic-light/resolve/main/iclight_sd15_fcon.safetensors"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-SUPIR",
    "reference": "https://github.com/kijai/ComfyUI-SUPIR",
    "models": {
      "files": [
        {
          "name": "SUPIR/SUPIR-v0F_fp16.safetensors",
          "type": "SUPIR",
          "base": "SUPIR",
          "save_path": "checkpoints/SUPIR",
          "description": "Training with light degradation settings. Stage1 encoder of SUPIR-v0F remains more details when facing light degradations",
          "reference": "https://huggingface.co/Kijai/SUPIR_pruned",
          "filename": "SUPIR-v0F_fp16.safetensors",
          "url": "https://huggingface.co/Kijai/SUPIR_pruned/resolve/main/SUPIR-v0F_fp16.safetensors"
        },
        {
          "name": "SUPIR/SUPIR-v0Q_fp16.safetensors",
          "type": "SUPIR",
          "base": "SUPIR",
          "save_path": "checkpoints/SUPIR",
          "description": "Default training settings with paper. High generalization and high image quality in most cases",
          "reference": "https://huggingface.co/Kijai/SUPIR_pruned",
          "filename": "SUPIR-v0Q_fp16.safetensors",
          "url": "https://huggingface.co/Kijai/SUPIR_pruned/resolve/main/SUPIR-v0Q_fp16.safetensors"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-ELLA",
    "reference": "https://github.com/TencentQQGYLab/ComfyUI-ELLA",
    "models": {
      "files": [
        {
          "name": "ella/ella-sd1.5-tsc-t5xl.safetensors",
          "type": "ella",
          "base": "SD1.5",
          "save_path": "ella",
          "description": "ELLA Models",
          "reference": "https://huggingface.co/QQGYLab/ELLA",
          "filename": "ella-sd1.5-tsc-t5xl.safetensors",
          "url": "https://huggingface.co/QQGYLab/ELLA/resolve/main/ella-sd1.5-tsc-t5xl.safetensors"
        },
        {
          "name": "ella/ella_encoder/config.json",
          "type": "ella",
          "base": "SD1.5",
          "save_path": "ella_encoder/models--google--flan-t5-xl--text_encoder",
          "description": "ELLA encoder folder",
          "reference": "https://huggingface.co/QQGYLab/ELLA",
          "filename": "config.json",
          "url": "https://huggingface.co/QQGYLab/ELLA/resolve/main/models--google--flan-t5-xl--text_encoder/config.json"
        },
        {
          "name": "ella/ella_encoder/model.safetensors",
          "type": "ella",
          "base": "SD1.5",
          "save_path": "ella_encoder/models--google--flan-t5-xl--text_encoder",
          "description": "ELLA encoder folder",
          "reference": "https://huggingface.co/QQGYLab/ELLA",
          "filename": "model.safetensors",
          "url": "https://huggingface.co/QQGYLab/ELLA/resolve/main/models--google--flan-t5-xl--text_encoder/model.safetensors"
        },
        {
          "name": "ella/ella_encoder/special_tokens_map.json",
          "type": "ella",
          "base": "SD1.5",
          "save_path": "ella_encoder/models--google--flan-t5-xl--text_encoder",
          "description": "ELLA encoder folder",
          "reference": "https://huggingface.co/QQGYLab/ELLA",
          "filename": "special_tokens_map.json",
          "url": "https://huggingface.co/QQGYLab/ELLA/resolve/main/models--google--flan-t5-xl--text_encoder/special_tokens_map.json"
        },
        {
          "name": "ella/ella_encoder/spiece.model",
          "type": "ella",
          "base": "SD1.5",
          "save_path": "ella_encoder/models--google--flan-t5-xl--text_encoder",
          "description": "ELLA encoder folder",
          "reference": "https://huggingface.co/QQGYLab/ELLA",
          "filename": "spiece.model",
          "url": "https://huggingface.co/QQGYLab/ELLA/resolve/main/models--google--flan-t5-xl--text_encoder/spiece.model"
        },
        {
          "name": "ella/ella_encoder/tokenizer.json",
          "type": "ella",
          "base": "SD1.5",
          "save_path": "ella_encoder/models--google--flan-t5-xl--text_encoder",
          "description": "ELLA encoder folder",
          "reference": "https://huggingface.co/QQGYLab/ELLA",
          "filename": "tokenizer.json",
          "url": "https://huggingface.co/QQGYLab/ELLA/resolve/main/models--google--flan-t5-xl--text_encoder/tokenizer.json"
        },
        {
          "name": "ella/ella_encoder/tokenizer_config.json",
          "type": "ella",
          "base": "SD1.5",
          "save_path": "ella_encoder/models--google--flan-t5-xl--text_encoder",
          "description": "ELLA encoder folder",
          "reference": "https://huggingface.co/QQGYLab/ELLA",
          "filename": "tokenizer_config.json",
          "url": "https://huggingface.co/QQGYLab/ELLA/resolve/main/models--google--flan-t5-xl--text_encoder/tokenizer_config.json"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-YoloWorld-EfficientSAM",
    "reference": "https://github.com/ZHO-ZHO-ZHO/ComfyUI-YoloWorld-EfficientSAM",
    "models": {
      "files": [
        {
          "name": "EfficientSAM/efficient_sam_s_cpu.jit",
          "type": "EfficientSAM",
          "base": "",
          "save_path": "custom_nodes/ComfyUI-YoloWorld-EfficientSAM",
          "description": "Efficient SAM",
          "reference": "https://huggingface.co/camenduru/YoloWorld-EfficientSAM",
          "filename": "efficient_sam_s_cpu.jit",
          "url": "https://huggingface.co/camenduru/YoloWorld-EfficientSAM/resolve/main/efficient_sam_s_cpu.jit"
        },
        {
          "name": "EfficientSAM/efficient_sam_s_gpu.jit",
          "type": "EfficientSAM",
          "base": "",
          "save_path": "custom_nodes/ComfyUI-YoloWorld-EfficientSAM",
          "description": "Efficient SAM",
          "reference": "https://huggingface.co/camenduru/YoloWorld-EfficientSAM",
          "filename": "efficient_sam_s_gpu.jit",
          "url": "https://huggingface.co/camenduru/YoloWorld-EfficientSAM/resolve/main/efficient_sam_s_gpu.jit"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-ToonCrafter",
    "reference": "https://github.com/AIGODLIKE/ComfyUI-ToonCrafter",
    "models": {
      "files": [
        {
          "name": "ToonCrafter/tooncrafter_512_interp-fp16.safetensors",
          "type": "ToonCrafter",
          "base": "",
          "save_path": "custom_nodes/ComfyUI-ToonCrafter/ToonCrafter/checkpoints/tooncrafter_512_interp_v1",
          "description": "tooncrafter_512_interp-fp16",
          "reference": "https://huggingface.co/Kijai/DynamiCrafter_pruned",
          "filename": "tooncrafter_512_interp-fp16.safetensors",
          "url": "https://huggingface.co/Kijai/DynamiCrafter_pruned/resolve/main/tooncrafter_512_interp-fp16.safetensors"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-DynamiCrafterWrapper",
    "reference": "https://github.com/kijai/ComfyUI-DynamiCrafterWrapper",
    "models": {
      "files": [
        {
          "name": "DynamiCrafter/dynamicrafter_1024_v1_bf16.safetensors",
          "type": "DynamiCrafter",
          "base": "",
          "save_path": "checkpoints",
          "description": "dynamicrafter_1024_v1_bf16",
          "reference": "https://huggingface.co/Kijai/DynamiCrafter_pruned",
          "filename": "dynamicrafter_1024_v1_bf16.safetensors",
          "url": "https://huggingface.co/Kijai/DynamiCrafter_pruned/resolve/main/dynamicrafter_1024_v1_bf16.safetensors"
        },
        {
          "name": "DynamiCrafter/dynamicrafter_512_interp_v1_bf16.safetensors",
          "type": "DynamiCrafter",
          "base": "",
          "save_path": "checkpoints",
          "description": "dynamicrafter_512_interp_v1_bf16",
          "reference": "https://huggingface.co/Kijai/DynamiCrafter_pruned",
          "filename": "dynamicrafter_512_interp_v1_bf16.safetensors",
          "url": "https://huggingface.co/Kijai/DynamiCrafter_pruned/resolve/main/dynamicrafter_512_interp_v1_bf16.safetensors"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-Anyline",
    "reference": "https://github.com/TheMistoAI/ComfyUI-Anyline",
    "models": {
      "files": [
        {
          "name": "TheMistoAI/MTEED.pth",
          "type": "misto",
          "base": "",
          "save_path": "custom_nodes/ComfyUI-Anyline/checkpoints/Anyline",
          "description": "tooncrafter_512_interp-fp16",
          "reference": "https://huggingface.co/TheMistoAI/MistoLine",
          "filename": "MTEED.pth",
          "url": "https://huggingface.co/TheMistoAI/MistoLine/resolve/main/Anyline/MTEED.pth"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-AnyText",
    "reference": "https://github.com/zmwv823/ComfyUI-AnyText",
    "models": {
      "files": [
        {
          "name": "AnyText/anytext_v1.1.ckpt",
          "type": "",
          "base": "",
          "save_path": "checkpoints/15",
          "description": "anytext_v1.1.ckpt",
          "reference": "https://modelscope.cn/models/iic/cv_anytext_text_generation_editing",
          "filename": "anytext_v1.1.ckpt",
          "url": "https://modelscope.cn/models/iic/cv_anytext_text_generation_editing/file/view/master?fileName=anytext_v1.1.ckpt&status=2"
        },
        {
          "name": "AnyText/pytorch_model.fp16.safetensors",
          "type": "",
          "base": "",
          "save_path": "checkpoints/15",
          "description": "pytorch_model.fp16",
          "reference": "https://huggingface.co/Sanster/AnyText",
          "filename": "pytorch_model.fp16.safetensors",
          "url": "https://huggingface.co/Sanster/AnyText/blob/main/pytorch_model.fp16.safetensors"
        },
        {
          "name": "AnyText/SourceHanSansSC-Medium.otf",
          "type": "",
          "base": "",
          "save_path": "fonts",
          "description": "SourceHanSansSC-Medium",
          "reference": "https://huggingface.co/Sanster/AnyText",
          "filename": "SourceHanSansSC-Medium.otf",
          "url": "https://huggingface.co/Sanster/AnyText/blob/main/SourceHanSansSC-Medium.otf"
        },
        {
          "name": "AnyText/clip-vit-large-patch14/config.json",
          "type": "",
          "base": "",
          "save_path": "clip/openai--clip-vit-large-patch14",
          "description": "openai--clip-vit-large-patch14",
          "reference": "https://huggingface.co/openai/clip-vit-large-patch14",
          "filename": "config.json",
          "url": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/config.json"
        },
        {
          "name": "AnyText/clip-vit-large-patch14/flax_model.msgpack",
          "type": "",
          "base": "",
          "save_path": "clip/openai--clip-vit-large-patch14",
          "description": "openai--clip-vit-large-patch14",
          "reference": "https://huggingface.co/openai/clip-vit-large-patch14",
          "filename": "flax_model.msgpack",
          "url": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/flax_model.msgpack"
        },
        {
          "name": "AnyText/clip-vit-large-patch14/merges.txt",
          "type": "",
          "base": "",
          "save_path": "clip/openai--clip-vit-large-patch14",
          "description": "openai--clip-vit-large-patch14",
          "reference": "https://huggingface.co/openai/clip-vit-large-patch14",
          "filename": "merges.txt",
          "url": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/merges.txt"
        },
        {
          "name": "AnyText/clip-vit-large-patch14/pytorch_model.bin",
          "type": "",
          "base": "",
          "save_path": "clip/openai--clip-vit-large-patch14",
          "description": "openai--clip-vit-large-patch14",
          "reference": "https://huggingface.co/openai/clip-vit-large-patch14",
          "filename": "pytorch_model.bin",
          "url": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin"
        },
        {
          "name": "AnyText/clip-vit-large-patch14/pytorch_model.bin",
          "type": "",
          "base": "",
          "save_path": "clip/openai--clip-vit-large-patch14",
          "description": "openai--clip-vit-large-patch14",
          "reference": "https://huggingface.co/openai/clip-vit-large-patch14",
          "filename": "pytorch_model.bin",
          "url": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin"
        },
        {
          "name": "AnyText/clip-vit-large-patch14/special_tokens_map.json",
          "type": "",
          "base": "",
          "save_path": "clip/openai--clip-vit-large-patch14",
          "description": "openai--clip-vit-large-patch14",
          "reference": "https://huggingface.co/openai/clip-vit-large-patch14",
          "filename": "special_tokens_map.json",
          "url": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/special_tokens_map.json"
        },
        {
          "name": "AnyText/clip-vit-large-patch14/tf_model.h5",
          "type": "",
          "base": "",
          "save_path": "clip/openai--clip-vit-large-patch14",
          "description": "openai--clip-vit-large-patch14",
          "reference": "https://huggingface.co/openai/clip-vit-large-patch14",
          "filename": "tf_model.h5",
          "url": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/tf_model.h5"
        },
        {
          "name": "AnyText/clip-vit-large-patch14/tokenizer.json",
          "type": "",
          "base": "",
          "save_path": "clip/openai--clip-vit-large-patch14",
          "description": "openai--clip-vit-large-patch14",
          "reference": "https://huggingface.co/openai/clip-vit-large-patch14",
          "filename": "tokenizer.json",
          "url": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/tokenizer.json"
        },
        {
          "name": "AnyText/clip-vit-large-patch14/tokenizer_config.json",
          "type": "",
          "base": "",
          "save_path": "clip/openai--clip-vit-large-patch14",
          "description": "openai--clip-vit-large-patch14",
          "reference": "https://huggingface.co/openai/clip-vit-large-patch14",
          "filename": "tokenizer_config.json",
          "url": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/tokenizer_config.json"
        },
        {
          "name": "AnyText/clip-vit-large-patch14/vocab.json",
          "type": "",
          "base": "",
          "save_path": "clip/openai--clip-vit-large-patch14",
          "description": "openai--clip-vit-large-patch14",
          "reference": "https://huggingface.co/openai/clip-vit-large-patch14",
          "filename": "vocab.json",
          "url": "https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/vocab.json"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/tftf_ckpts/checkpoint",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2en/tftf_ckpts",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "checkpoint",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=tf_ckpts%2Fcheckpoint"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/tftf_ckpts/ckpt-0.data-00000-of-00001",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2e/tftf_ckptsn",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "ckpt-0.data-00000-of-00001",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=tf_ckpts%2Fckpt-0.data-00000-of-00001"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/tftf_ckpts/ckpt-0.index",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2en/tftf_ckpts",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "ckpt-0.index",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=tf_ckpts%2Fckpt-0.index"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/tftf_ckpts/ckpt-0.meta",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2en/tftf_ckpts",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "ckpt-0.meta",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=tf_ckpts%2Fckpt-0.meta"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/bpe.en",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2en",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "bpe.en",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=bpe.en"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/bpe.zh",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2en",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "bpe.zh",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=bpe.zh"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/configuration.json",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2en",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "configuration.json",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=configuration.json"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/README.md",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2en",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "README.md",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=README.md"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/src_vocab.txt",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2en",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "src_vocab.txt",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=src_vocab.txt"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/train.en",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2en",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "train.en",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=train.en"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/train.zh",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2en",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "train.zh",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=train.zh"
        },
        {
          "name": "AnyText/nlp_csanmt_translation_zh2en/trg_vocab.txt",
          "type": "",
          "base": "",
          "save_path": "prompt_generator/nlp_csanmt_translation_zh2en",
          "description": "nlp_csanmt_translation_zh2en",
          "reference": "https://www.modelscope.cn/models/iic/nlp_csanmt_translation_zh2en",
          "filename": "trg_vocab.txt",
          "url": "https://www.modelscope.cn/api/v1/models/iic/nlp_csanmt_translation_zh2en/repo?Revision=master&FilePath=trg_vocab.txt"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-AnimateDiff-Evolved",
    "reference": "https://github.com/Kosinkadink/ComfyUI-AnimateDiff-Evolved",
    "models": {
      "files": [
        {
          "name": "AnimateDiff/mm_sd_v14",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_models",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/models",
          "description": "mm_sd_v14.ckpt",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "mm_sd_v14.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/cd71ae134a27ec6008b968d6419952b0c0494cf2/mm_sd_v14.ckpt"
        },
        {
          "name": "AnimateDiff/mm_sd_v15",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_models",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/models",
          "description": "mm_sd_v15.ckpt",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "mm_sd_v15.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/cd71ae134a27ec6008b968d6419952b0c0494cf2/mm_sd_v15.ckpt"
        },
        {
          "name": "AnimateDiff/mm_sd_v15_v2",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_models",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/models",
          "description": "mm_sd_v15_v2.ckpt",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "mm_sd_v15_v2.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/cd71ae134a27ec6008b968d6419952b0c0494cf2/mm_sd_v15_v2.ckpt"
        },
        {
          "name": "AnimateDiff/v3_sd15_mm",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_models",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/models",
          "description": "v3_sd15_mm.ckpt",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v3_sd15_mm.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/cd71ae134a27ec6008b968d6419952b0c0494cf2/v3_sd15_mm.ckpt"
        },
        {
          "name": "AnimateDiff/mm-Stabilized_high",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_models",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/models",
          "description": "Stabilized finetunes of mm_sd_v14",
          "reference": "https://huggingface.co/manshoety/AD_Stabilized_Motion",
          "filename": "mm-Stabilized_high.pth",
          "url": "https://huggingface.co/manshoety/AD_Stabilized_Motion/resolve/main/mm-Stabilized_high.pth"
        },
        {
          "name": "AnimateDiff/mm-Stabilized_mid",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_models",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/models",
          "description": "Stabilized finetunes of mm_sd_v14",
          "reference": "https://huggingface.co/manshoety/AD_Stabilized_Motion",
          "filename": "mm-Stabilized_mid.pth",
          "url": "https://huggingface.co/manshoety/AD_Stabilized_Motion/resolve/main/mm-Stabilized_mid.pth"
        },
        {
          "name": "AnimateDiff/mm-p_0.5",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_models",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/models",
          "description": "Finetunes of mm_sd_v15_v2",
          "reference": "https://huggingface.co/manshoety/beta_testing_models",
          "filename": "mm-p_0.5.pth",
          "url": "https://huggingface.co/manshoety/beta_testing_models/resolve/main/mm-p_0.5.pth"
        },
        {
          "name": "AnimateDiff/mm-p_0.75",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_models",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/models",
          "description": "Finetunes of mm_sd_v15_v2",
          "reference": "https://huggingface.co/manshoety/beta_testing_models",
          "filename": "mm-p_0.75.pth",
          "url": "https://huggingface.co/manshoety/beta_testing_models/resolve/main/mm-p_0.75.pth"
        },
        {
          "name": "AnimateDiff/temporaldiff-v1-animatediff",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_models",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/models",
          "description": "Higher resolution finetune",
          "reference": "https://huggingface.co/CiaraRowles/TemporalDiff",
          "filename": "temporaldiff-v1-animatediff.safetensors",
          "url": "https://huggingface.co/CiaraRowles/TemporalDiff/resolve/main/temporaldiff-v1-animatediff.safetensors"
        },
        {
          "name": "AnimateDiff/v2_lora_PanLeft",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_motion_lora",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/motion_lora",
          "description": "Motion LoRAs to influence movement of v2-based motion models like mm_sd_v15_v2",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v2_lora_PanLeft.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_PanLeft.ckpt"
        },
        {
          "name": "AnimateDiff/v2_lora_PanRight",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_motion_lora",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/motion_lora",
          "description": "Motion LoRAs to influence movement of v2-based motion models like mm_sd_v15_v2",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v2_lora_PanRight.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_PanRight.ckpt"
        },
        {
          "name": "AnimateDiff/v2_lora_RollingAnticlockwise",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_motion_lora",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/motion_lora",
          "description": "Motion LoRAs to influence movement of v2-based motion models like mm_sd_v15_v2",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v2_lora_RollingAnticlockwise.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_RollingAnticlockwise.ckpt"
        },
        {
          "name": "AnimateDiff/v2_lora_RollingClockwise",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_motion_lora",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/motion_lora",
          "description": "Motion LoRAs to influence movement of v2-based motion models like mm_sd_v15_v2",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v2_lora_RollingClockwise.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_RollingClockwise.ckpt"
        },
        {
          "name": "AnimateDiff/v2_lora_TiltDown",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_motion_lora",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/motion_lora",
          "description": "Motion LoRAs to influence movement of v2-based motion models like mm_sd_v15_v2",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v2_lora_TiltDown.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_TiltDown.ckpt"
        },
        {
          "name": "AnimateDiff/v2_lora_ZoomIn",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_motion_lora",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/motion_lora",
          "description": "Motion LoRAs to influence movement of v2-based motion models like mm_sd_v15_v2",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v2_lora_ZoomIn.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_ZoomIn.ckpt"
        },
        {
          "name": "AnimateDiff/v2_lora_ZoomOut",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_motion_lora",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/motion_lora",
          "description": "Motion LoRAs to influence movement of v2-based motion models like mm_sd_v15_v2",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v2_lora_ZoomOut.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_ZoomOut.ckpt"
        },
        {
          "name": "AnimateDiff/v3_sd15_adapter",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_motion_lora",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/motion_lora",
          "description": "Motion LoRAs to influence movement of v2-based motion models like mm_sd_v15_v2",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v3_sd15_adapter.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/main/v3_sd15_adapter.ckpt"
        },
        {
          "name": "AnimateDiff/v3_sd15_mm",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_motion_lora",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/motion_lora",
          "description": "Motion LoRAs to influence movement of v2-based motion models like mm_sd_v15_v2",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v3_sd15_mm.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/main/v3_sd15_mm.ckpt"
        },
        {
          "name": "AnimateDiff/v3_sd15_sparsectrl_rgb",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_motion_lora",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/motion_lora",
          "description": "Motion LoRAs to influence movement of v2-based motion models like mm_sd_v15_v2",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v3_sd15_sparsectrl_rgb.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/main/v3_sd15_sparsectrl_rgb.ckpt"
        },
        {
          "name": "AnimateDiff/v3_sd15_sparsectrl_scribble",
          "type": "AnimateDiff",
          "base": "",
          "save_path": "animatediff_motion_lora",
          "save_path_2": "custom_nodes/ComfyUI-AnimateDiff-Evolved/motion_lora",
          "description": "Motion LoRAs to influence movement of v2-based motion models like mm_sd_v15_v2",
          "reference": "https://huggingface.co/guoyww/animatediff",
          "filename": "v3_sd15_sparsectrl_scribble.ckpt",
          "url": "https://huggingface.co/guoyww/animatediff/resolve/main/v3_sd15_sparsectrl_scribble.ckpt"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-BRIA_AI-RMBG",
    "reference": "https://github.com/ZHO-ZHO-ZHO/ComfyUI-BRIA_AI-RMBG",
    "models": {
      "files": [
        {
          "name": "BRIA/model",
          "type": "BRIA",
          "base": "",
          "save_path": "custom_nodes/ComfyUI-BRIA_AI-RMBG/RMBG-1.4",
          "description": "BRIA Background Removal v1.4 Model",
          "reference": "https://huggingface.co/briaai/RMBG-1.4",
          "filename": "model.pth",
          "url": "https://huggingface.co/briaai/RMBG-1.4/resolve/main/model.pth"
        }
      ]
    }
  },
  {
    "custom_node": "Comfyui-MusePose",
    "reference": "https://github.com/TMElyralab/Comfyui-MusePose",
    "models": {
      "files": [
        {
          "name": "MusePose/denoising_unet",
          "type": "MusePose",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/MusePose",
          "save_path_2": "",
          "description": "MusePose models",
          "reference": "https://huggingface.co/TMElyralab/MusePose",
          "filename": "denoising_unet.pth",
          "url": "https://huggingface.co/TMElyralab/MusePose/resolve/main/MusePose/denoising_unet.pth"
        },
        {
          "name": "MusePose/motion_module",
          "type": "MusePose",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/MusePose",
          "save_path_2": "",
          "description": "MusePose models",
          "reference": "https://huggingface.co/TMElyralab/MusePose",
          "filename": "motion_module.pth",
          "url": "https://huggingface.co/TMElyralab/MusePose/resolve/main/MusePose/motion_module.pth"
        },
        {
          "name": "MusePose/pose_guider",
          "type": "MusePose",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/MusePose",
          "save_path_2": "",
          "description": "MusePose models",
          "reference": "https://huggingface.co/TMElyralab/MusePose",
          "filename": "pose_guider.pth",
          "url": "https://huggingface.co/TMElyralab/MusePose/resolve/main/MusePose/pose_guider.pth"
        },
        {
          "name": "MusePose/reference_unet",
          "type": "MusePose",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/MusePose",
          "save_path_2": "",
          "description": "MusePose models",
          "reference": "https://huggingface.co/TMElyralab/MusePose",
          "filename": "reference_unet.pth",
          "url": "https://huggingface.co/TMElyralab/MusePose/resolve/main/MusePose/reference_unet.pth"
        },
        {
          "name": "dwpose/dw-ll_ucoco_384",
          "type": "dwpose",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/dwpose",
          "save_path_2": "",
          "description": "dwpose models",
          "reference": "https://huggingface.co/yzd-v/DWPose",
          "filename": "dw-ll_ucoco_384.pth",
          "url": "https://huggingface.co/yzd-v/DWPose/resolve/main/dw-ll_ucoco_384.pth"
        },
        {
          "name": "dwpose/yolox_l_8x8_300e_coco",
          "type": "dwpose",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/dwpose",
          "save_path_2": "",
          "description": "yolox models",
          "reference": "https://openmmlab.com/",
          "filename": "yolox_l_8x8_300e_coco.pth",
          "url": "https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_l_8x8_300e_coco/yolox_l_8x8_300e_coco_20211126_140236-d3bd2b23.pth"
        },
        {
          "name": "sd-image-variations-diffusers/unet/config.json",
          "type": "",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/sd-image-variations-diffusers/unet",
          "save_path_2": "",
          "description": "Stable Diffusion Image Variations Model",
          "reference": "https://huggingface.co/lambdalabs/sd-image-variations-diffusers",
          "filename": "config.json",
          "url": "https://huggingface.co/lambdalabs/sd-image-variations-diffusers/resolve/main/unet/config.json"
        },
        {
          "name": "sd-image-variations-diffusers/unet/diffusion_pytorch_model.bin",
          "type": "",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/sd-image-variations-diffusers/unet",
          "save_path_2": "",
          "description": "Stable Diffusion Image Variations Model",
          "reference": "https://huggingface.co/lambdalabs/sd-image-variations-diffusers",
          "filename": "diffusion_pytorch_model.bin",
          "url": "https://huggingface.co/lambdalabs/sd-image-variations-diffusers/resolve/main/unet/diffusion_pytorch_model.bin"
        },
        {
          "name": "sd-image-variations-diffusers/image_encoder/config.json",
          "type": "",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/image_encoder",
          "save_path_2": "",
          "description": "Stable Diffusion Image Variations Model",
          "reference": "https://huggingface.co/lambdalabs/sd-image-variations-diffusers",
          "filename": "config.json",
          "url": "https://huggingface.co/lambdalabs/sd-image-variations-diffusers/resolve/main/image_encoder/config.json"
        },
        {
          "name": "sd-image-variations-diffusers/image_encoder/pytorch_model.bin",
          "type": "",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/image_encoder",
          "save_path_2": "",
          "description": "Stable Diffusion Image Variations Model",
          "reference": "https://huggingface.co/lambdalabs/sd-image-variations-diffusers",
          "filename": "pytorch_model.bin",
          "url": "https://huggingface.co/lambdalabs/sd-image-variations-diffusers/resolve/main/image_encoder/pytorch_model.bin"
        },
        {
          "name": "sd-vae-ft-mse/config.json",
          "type": "",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/sd-vae-ft-mse",
          "save_path_2": "",
          "description": "Stable Diffusion Vae",
          "reference": "https://huggingface.co/stabilityai/sd-vae-ft-mse",
          "filename": "config.json",
          "url": "https://huggingface.co/lambdalabs/sd-image-variations-diffusers/resolve/main/image_encoder/config.json"
        },
        {
          "name": "sd-vae-ft-mse/diffusion_pytorch_model.bin",
          "type": "",
          "base": "",
          "save_path": "custom_nodes/Comfyui-MusePose/pretrained_weights/sd-vae-ft-mse",
          "save_path_2": "",
          "description": "Stable Diffusion Vae",
          "reference": "https://huggingface.co/stabilityai/sd-vae-ft-mse",
          "filename": "diffusion_pytorch_model.bin",
          "url": "https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-KwaiKolorsWrapper",
    "reference": "https://github.com/kijai/ComfyUI-KwaiKolorsWrapper",
    "models": {
      "files": [
        {
          "name": "KwaiKolorsWrapper/chatglm3-4bit",
          "type": "Kolors",
          "base": "",
          "save_path": "LLM",
          "save_path_2": "",
          "description": "chatglm3 4bit model",
          "reference": "https://huggingface.co/Kijai/ChatGLM3-safetensors",
          "filename": "chatglm3-4bit.safetensors",
          "url": "https://huggingface.co/Kijai/ChatGLM3-safetensors/resolve/main/chatglm3-4bit.safetensors"
        },
        {
          "name": "KwaiKolorsWrapper/chatglm3-8bit",
          "type": "Kolors",
          "base": "",
          "save_path": "LLM",
          "save_path_2": "",
          "description": "chatglm3 8bit model",
          "reference": "https://huggingface.co/Kijai/ChatGLM3-safetensors",
          "filename": "chatglm3-8bit.safetensors",
          "url": "https://huggingface.co/Kijai/ChatGLM3-safetensors/resolve/main/chatglm3-8bit.safetensors"
        },
        {
          "name": "KwaiKolorsWrapper/chatglm3-fp16",
          "type": "Kolors",
          "base": "",
          "save_path": "LLM",
          "save_path_2": "",
          "description": "chatglm3 fp16 model",
          "reference": "https://huggingface.co/Kijai/ChatGLM3-safetensors",
          "filename": "chatglm3-fp16.safetensors",
          "url": "https://huggingface.co/Kijai/ChatGLM3-safetensors/resolve/main/chatglm3-fp16.safetensors"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-Kolors-MZ",
    "reference": "https://github.com/MinusZoneAI/ComfyUI-Kolors-MZ",
    "models": {
      "files": [
        {
          "name": "KwaiKolorsWrapper/chatglm3-4bit",
          "type": "Kolors",
          "base": "",
          "save_path": "LLM",
          "save_path_2": "",
          "description": "chatglm3 4bit model",
          "reference": "https://huggingface.co/Kijai/ChatGLM3-safetensors",
          "filename": "chatglm3-4bit.safetensors",
          "url": "https://huggingface.co/Kijai/ChatGLM3-safetensors/resolve/main/chatglm3-4bit.safetensors"
        },
        {
          "name": "KwaiKolorsWrapper/chatglm3-8bit",
          "type": "Kolors",
          "base": "",
          "save_path": "LLM",
          "save_path_2": "",
          "description": "chatglm3 8bit model",
          "reference": "https://huggingface.co/Kijai/ChatGLM3-safetensors",
          "filename": "chatglm3-8bit.safetensors",
          "url": "https://huggingface.co/Kijai/ChatGLM3-safetensors/resolve/main/chatglm3-8bit.safetensors"
        },
        {
          "name": "KwaiKolorsWrapper/chatglm3-fp16",
          "type": "Kolors",
          "base": "",
          "save_path": "LLM",
          "save_path_2": "",
          "description": "chatglm3 fp16 model",
          "reference": "https://huggingface.co/Kijai/ChatGLM3-safetensors",
          "filename": "chatglm3-fp16.safetensors",
          "url": "https://huggingface.co/Kijai/ChatGLM3-safetensors/resolve/main/chatglm3-fp16.safetensors"
        },
        {
          "name": "KwaiKolorsWrapper/kolors-unet",
          "type": "Kolors",
          "base": "",
          "save_path": "unet/kolors",
          "save_path_2": "",
          "description": "kolors unet model",
          "reference": "https://huggingface.co/Kwai-Kolors/Kolors",
          "filename": "kolors-unet.safetensors",
          "url": "https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/unet/diffusion_pytorch_model.fp16.safetensors"
        }
      ]
    }
  },
  {
    "custom_node": "ComfyUI-AuraSR-ZHO",
    "reference": "https://github.com/ZHO-ZHO-ZHO/ComfyUI-AuraSR-ZHO",
    "models": {
      "files": [
        {
          "name": "AuraSR model",
          "type": "AuraSR",
          "base": "",
          "save_path": "aurasr",
          "save_path_2": "",
          "description": "AuraSR model",
          "reference": "https://huggingface.co/fal/AuraSR",
          "filename": "model.safetensors",
          "url": "https://huggingface.co/fal/AuraSR/resolve/main/model.safetensors"
        }
      ]
    }
  }

]

